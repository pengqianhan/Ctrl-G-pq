{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ctrl-G Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Part A**. Ctrl-G on GPT2-large (less computation required)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1. load pretrained models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "device = 'cuda'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0' # set your cuda device\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "\n",
    "import torch\n",
    "import ctrlg\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, LogitsProcessorList\n",
    "\n",
    "# load the pretrained base_model and hmm_model; see README.md for a complete list of \n",
    "# released checkpoints. note that the hmm_model and base_model must share the same \n",
    "# vocabulary of tokens: i.e., one cannot apply hmm_gpt2-large_common-gen_4096 to \n",
    "# tulu2-7b_writing-prompts. To apply Ctrl-G to a custom base_model or to achieve \n",
    "# best performance on a specific domain, users would need to distill an hmm_model\n",
    "# from the base_model. Please refer to tutorial_distillation.ipynb for details.\n",
    "BASE_MODEL_PATH = f'ctrlg/gpt2-large_common-gen' # a gpt2-large checkpoint domain adapted to the common-gen corpus\n",
    "HMM_MODEL_PATH = f'ctrlg/hmm_gpt2-large_common-gen_4096' # alternatively 'ctrlg/hmm_gpt2-large_common-gen_32768' for better quality\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(BASE_MODEL_PATH).to(device)\n",
    "base_model.eval()\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_PATH)\n",
    "hmm_model = ctrlg.HMM.from_pretrained(HMM_MODEL_PATH).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2. specify logical constraints as DFAs (example constraint 1)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patterns [[10311, 257, 7161], [6594, 16715], [17445, 257, 7161], [38088], [16715]]\n",
      "ac_builder.build(patterns) {'edges': [((), (10311,), array([False, False, False, ..., False, False, False])), ((), (17445,), array([False, False, False, ..., False, False, False])), ((), (38088,), array([False, False, False, ..., False, False, False])), ((), (16715,), array([False, False, False, ..., False, False, False])), ((), (), array([ True,  True,  True, ...,  True,  True,  True])), ((10311,), (10311, 257), array([False, False, False, ..., False, False, False])), ((10311,), (17445,), array([False, False, False, ..., False, False, False])), ((10311,), (10311,), array([False, False, False, ..., False, False, False])), ((10311,), (38088,), array([False, False, False, ..., False, False, False])), ((10311,), (16715,), array([False, False, False, ..., False, False, False])), ((10311,), (), array([ True,  True,  True, ...,  True,  True,  True])), ((10311, 257), (10311, 257, 7161), array([False, False, False, ..., False, False, False])), ((10311, 257), (), array([ True,  True,  True, ...,  True,  True,  True])), ((10311, 257), (17445,), array([False, False, False, ..., False, False, False])), ((10311, 257), (10311,), array([False, False, False, ..., False, False, False])), ((10311, 257), (38088,), array([False, False, False, ..., False, False, False])), ((10311, 257), (16715,), array([False, False, False, ..., False, False, False])), ((17445,), (17445, 257), array([False, False, False, ..., False, False, False])), ((17445,), (17445,), array([False, False, False, ..., False, False, False])), ((17445,), (10311,), array([False, False, False, ..., False, False, False])), ((17445,), (38088,), array([False, False, False, ..., False, False, False])), ((17445,), (16715,), array([False, False, False, ..., False, False, False])), ((17445,), (), array([ True,  True,  True, ...,  True,  True,  True])), ((17445, 257), (17445, 257, 7161), array([False, False, False, ..., False, False, False])), ((17445, 257), (), array([ True,  True,  True, ...,  True,  True,  True])), ((17445, 257), (17445,), array([False, False, False, ..., False, False, False])), ((17445, 257), (10311,), array([False, False, False, ..., False, False, False])), ((17445, 257), (38088,), array([False, False, False, ..., False, False, False])), ((17445, 257), (16715,), array([False, False, False, ..., False, False, False])), ((38088,), (38088,), array([ True,  True,  True, ...,  True,  True,  True])), ((17445, 257, 7161), (17445, 257, 7161), array([ True,  True,  True, ...,  True,  True,  True])), ((16715,), (16715,), array([ True,  True,  True, ...,  True,  True,  True])), ((10311, 257, 7161), (10311, 257, 7161), array([ True,  True,  True, ...,  True,  True,  True]))], 'initial_state': (), 'accept_states': {(38088,), (17445, 257, 7161), (16715,), (10311, 257, 7161)}}\n",
      "patterns [[3952], [10481]]\n",
      "ac_builder.build(patterns) {'edges': [((), (3952,), array([False, False, False, ..., False, False, False])), ((), (10481,), array([False, False, False, ..., False, False, False])), ((), (), array([ True,  True,  True, ...,  True,  True,  True])), ((10481,), (10481,), array([ True,  True,  True, ...,  True,  True,  True])), ((3952,), (3952,), array([ True,  True,  True, ...,  True,  True,  True]))], 'initial_state': (), 'accept_states': {(10481,), (3952,)}}\n"
     ]
    }
   ],
   "source": [
    "vocab_size = hmm_model.vocab_size##50257\n",
    "eos_token_id = hmm_model.eos_token_id##50256\n",
    "\n",
    "##################################### prefix, suffix, prompt #####################################\n",
    "prefix = '' # generate text starting with nothing\n",
    "suffix = '<|endoftext|>' # generate text ending with '<|endoftext|>'; a suffix must end with the eos token\n",
    "prompt = '<|endoftext|>' # prompt the base model with the '<|endoftext|>' token\n",
    "\n",
    "prefix_ids = tokenizer.encode(prefix)##[]\n",
    "suffix_ids = tokenizer.encode(suffix)##[50256]\n",
    "prompt_ids = tokenizer.encode(prompt)##[50256]\n",
    "##################################### prefix, suffix, prompt #####################################\n",
    "\n",
    "\n",
    "##################################### DFA Construction #####################################\n",
    "# ac_builder constructs a DFA representing the constraint that (at least) \n",
    "# one the patterns must appear; a pattern is a sequence of token ids\n",
    "ac_builder = ctrlg.AhoCorasickBuilder(vocab_size)\n",
    "# word_count_builder constructs a DFA representing the constraint that \n",
    "# the generated text consists of a to b words; refer to the source code of\n",
    "# WordCountBuilder for the definition of a word.\n",
    "word_count_builder = ctrlg.WordCountBuilder(tokenizer, vocab_size)\n",
    "\n",
    "dfa_graphs = []\n",
    "\n",
    "# constraint 1:\n",
    "# one of ' riding a bike', ' ride bikes', ' rides a bike', ' biking', ' bikes' has to appear\n",
    "# AND one of ' park', ' beach' has to appear\n",
    "keyphrases = [[' riding a bike', ' ride bikes', ' rides a bike', ' biking', ' bikes'],\n",
    "            [' park', ' beach']]\n",
    "for keyphrase in keyphrases:\n",
    "    patterns = [tokenizer.encode(x) for x in keyphrase]\n",
    "    '''\n",
    "    patterns [[10311, 257, 7161], [6594, 16715], [17445, 257, 7161], [38088], [16715]]\n",
    "    patterns [[3952], [10481]]\n",
    "    '''\n",
    "    # print('patterns', patterns)\n",
    "    # print('ac_builder.build(patterns)',ac_builder.build(patterns))\n",
    "\n",
    "    dfa_graphs.append(ac_builder.build(patterns))\n",
    "\n",
    "# constraint 2: generate exactly 10 words\n",
    "# word_count_builder constructs a DFA representing the constraint that \n",
    "# the generated text must contain a to b words\n",
    "a, b = 10, 10\n",
    "dfa_graphs.append(word_count_builder.build(a, b))\n",
    "\n",
    "# taking the intersection of the DFAs, i.e., \"logical and\" of the constraints.\n",
    "# This function also minimizes the constructed DFA, which is mainly CPU-based operations;\n",
    "# Due to its pure python implemenation, DFA minimization can be slow for complex constraints\n",
    "dfa_graph = ctrlg.DFA_prod(dfa_graphs, mode='intersection')\n",
    "\n",
    "# compile the dfa_graph for efficient GPU execution\n",
    "dfa_model = ctrlg.DFAModel(dfa_graph, vocab_size).to(device)\n",
    "##################################### DFA Construction #####################################\n",
    "\n",
    "\n",
    "##################################### token length #####################################\n",
    "# specify the min_new_tokens and max_new_tokens to be generated (excluding\n",
    "# the prefix and suffix) make sure that the numbers here would not conflict\n",
    "# with the given constraint: e.g. ask the model to generate 10 words with\n",
    "# max_new_tokens = 8\n",
    "min_new_tokens = 5\n",
    "max_new_tokens = 32\n",
    "##################################### token length #####################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3. generate with constraints.**\n",
    "\n",
    "Due to the use of @torch.compile, the first run of the following functions could be significantly slower than the later runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n",
      "[]\n",
      "[50256]\n",
      "Generated Samples:\n",
      "0  portrait of a man riding a bike in the park\n",
      "1  riding a bike in the park on a sunny day\n",
      "2  portrait of a man riding a bike in a park\n",
      "3  A man and woman riding a bike in the park.\n",
      "4  A man is riding a bike on a sandy beach.\n",
      "5  Two bikes are parked side by side on the beach.\n",
      "6  A man and woman riding a bike in a park.\n",
      "7  a man and woman riding a bike in the park\n",
      "8  portrait of a woman riding a bike in a park\n",
      "9  riding a bike in a park on a sunny day\n",
      "10  portrait of a woman riding a bike in the park\n",
      "11  Two bikes are parked on the side of the park.\n",
      "12  A woman is riding a bike on a sandy beach.\n",
      "13  A young boy is riding a bike in the park.\n",
      "14  riding a bike on the beach on a sunny day\n",
      "15  A young girl is riding a bike in the park.\n",
      "16  a man and woman riding a bike in a park\n",
      "17  Two bikes are parked side by side in a park.\n",
      "18  A man and woman riding a bike on the beach.\n",
      "19  portrait of a man riding a bike on the beach\n",
      "20  Two bikes are parked in the middle of the park.\n",
      "21  Two bikes are parked on the side of the beach.\n",
      "22  Two bikes are parked side by side in the park.\n",
      "23  portrait of a man riding a bike on a beach\n",
      "24  A young man is riding a bike in the park.\n",
      "25  a man riding a bike on the beach at sunset\n",
      "26  A young girl is riding a bike on the beach.\n",
      "27  A young girl is riding a bike in a park.\n",
      "28  A young boy is riding a bike on the beach.\n",
      "29  A young boy is riding a bike in a park.\n",
      "30  Two bikes are parked side by side on a beach.\n",
      "31  The bikes are parked on the side of the park.\n",
      "32  Two bikes are parked on the side of a park.\n",
      "33  bikes on the beach at the end of the day\n",
      "34  portrait of a woman riding a bike on the beach\n",
      "35  A young man is riding a bike on the beach.\n",
      "36  Two bikes are parked in the middle of a park.\n",
      "37  A young man is riding a bike in a park.\n",
      "38  a man and woman riding a bike on the beach\n",
      "39  portrait of a woman riding a bike on a beach\n",
      "40  riding a bike in the park on a sunny day.\n",
      "41  A man and woman riding a bike in the park\n",
      "42  A man and a woman are biking down a beach.\n",
      "43  a woman riding a bike on the beach at sunset\n",
      "44  A man and woman riding a bike on a beach.\n",
      "45  A man rides a bike on the beach at sunset.\n",
      "46  a man is riding a bike on a sandy beach\n",
      "47  riding a bike at the beach on a sunny day\n",
      "48  portrait of a man riding a bike at a park\n",
      "49  A man is biking down a road in a park.\n",
      "50  tourists riding a bike on the beach in the city\n",
      "51  A man and woman riding a bike at a park.\n",
      "52  A man riding a bike on the beach at sunset.\n",
      "53  A man is biking down the street in a park.\n",
      "54  A man and a woman are biking on the beach.\n",
      "55  The bikes are parked on the side of the beach.\n",
      "56  Two bikes are parked side by side on a park.\n",
      "57  Two bikes are parked on the side of a beach.\n",
      "58  A man and a woman are biking in the park.\n",
      "59  A man and a woman are biking down the beach.\n",
      "60  tourists riding a bike on a beach in the city\n",
      "61  a man rides a bike on the beach at sunset\n",
      "62  A man and woman riding a bike in a park\n",
      "63  man riding a bike on the beach in the morning\n",
      "64  riding a bike on a beach on a sunny day\n",
      "65  riding a bike in a park on a sunny day.\n",
      "66  a man and woman riding a bike on a beach\n",
      "67  portrait of a man riding a bike at the beach\n",
      "68  A man and woman riding a bike on a park.\n",
      "69  A man and a woman are biking on a beach.\n",
      "70  A young boy is riding a bike on a beach.\n",
      "71  Two bikes are parked side by side on the park.\n",
      "72  A young girl is riding a bike on a beach.\n",
      "73  A man is biking down the street on a beach.\n",
      "74  portrait of a woman riding a bike at a park\n",
      "75  A man and a woman are biking down a park.\n",
      "76  A man is riding a bike on a park bench.\n",
      "77  a man and woman riding a bike at a park\n",
      "78  A woman rides a bike on the beach at sunset.\n",
      "79  A woman riding a bike on the beach at sunset.\n",
      "80  A man and woman riding a bike on the beach\n",
      "81  A man and woman riding a bike at the beach.\n",
      "82  A young boy is riding a bike on a park.\n",
      "83  A young girl is riding a bike on a park.\n",
      "84  A young man is riding a bike on a beach.\n",
      "85  a woman rides a bike on the beach at sunset\n",
      "86  A man riding a bike on the beach at sunset\n",
      "87  riding a bike on the beach on a sunny day.\n",
      "88  A man rides a bike on the beach at sunset.\n",
      "89  portrait of a man riding a bike in a park.\n",
      "90  Two bikes are parked side by side on the beach\n",
      "91  A man is riding a bike on a sandy beach.\n",
      "92  A man rides a bike on the beach at sunset\n",
      "93  woman riding a bike on the beach in the morning\n",
      "94  A man is riding a bike on a sandy beach\n",
      "95  portrait of a man riding a bike in the park.\n",
      "96  A young man is riding a bike on a park.\n",
      "97  A man and a woman are biking on a park.\n",
      "98  A man and woman riding a bike in the park.\n",
      "99  man riding a bike on the beach in the city\n",
      "100  a man riding a bike on the beach at night\n",
      "101  man riding a bike in the park in the morning\n",
      "102  a man and woman riding a bike in the park.\n",
      "103  woman riding a bike on the beach in the city\n",
      "104  riding a bike on a sandy beach in the morning\n",
      "105  cyclists riding a bike on the beach in the city\n",
      "106  A man and woman riding a bike on a beach\n",
      "107  A woman riding a bike on the beach at sunset\n",
      "108  riding a bike at the beach on a sunny day.\n",
      "109  Two bikes are parked side by side on the beach.\n",
      "110  A woman is riding a bike on a sandy beach.\n",
      "111  person riding a bike on the beach in the morning\n",
      "112  A woman is riding a bike on a sandy beach\n",
      "113  A woman rides a bike on the beach at sunset.\n",
      "114  person riding a bike on the beach in the city\n",
      "115  A man rides a bike on the beach at night.\n",
      "116  portrait of a woman riding a bike in a park.\n",
      "117  bikes on the beach at the end of a day\n",
      "118  A girl riding a bike on the beach at sunset.\n",
      "119  a man and woman riding a bike on a park\n",
      "120  man riding a bike on a beach in the city\n",
      "121  A woman rides a bike on the beach at sunset\n",
      "122  a man is riding a bike on a sandy beach.\n",
      "123  A man riding a bike on the beach at sunset.\n",
      "124  woman riding a bike on a beach in the city\n",
      "125  portrait of a man riding a bike on a park\n",
      "126  portrait of a woman riding a bike in the park.\n",
      "127  tourists riding a bike in the park in the city\n"
     ]
    }
   ],
   "source": [
    "# initialze the constraints logits processor\n",
    "# Note: this part pre-computes & cache certain conditional probability tables;\n",
    "# one simple optimization is to re-use the same constraint_logits_processor for\n",
    "# base_model.generate if the constraints do not change.\n",
    "\n",
    "constraint_logits_processor = ctrlg.ConstraintLogitsProcessor(\n",
    "    hmm_model, dfa_model,\n",
    "    min_new_tokens, max_new_tokens,\n",
    "    prompt_ids, prefix_ids=prefix_ids, suffix_ids=suffix_ids)\n",
    "\n",
    "\n",
    "# set beam_size for beam search; usually the larger the beam_size the\n",
    "# higher the generation quality\n",
    "beam_size = 128\n",
    "\n",
    "# set the hmm_batch_size depending on the resource available;\n",
    "# uses more memory with larger hmm_batch_size but attains best speed \n",
    "# when it is set to beam_size\n",
    "constraint_logits_processor.hmm_batch_size = beam_size\n",
    "\n",
    "# generate with beam search\n",
    "input_ids = torch.tensor([prompt_ids], device=device)\n",
    "outputs = base_model.generate(\n",
    "        input_ids=input_ids, do_sample=False, length_penalty=0.2,\n",
    "        num_beams=beam_size, num_return_sequences=beam_size,\n",
    "        min_new_tokens=min_new_tokens, max_new_tokens=max_new_tokens,\n",
    "        logits_processor=LogitsProcessorList([constraint_logits_processor]),\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "    )\n",
    "# print('Generated Samples:', tokenizer.batch_decode(outputs, skip_special_tokens=True))\n",
    "print('Generated Samples:')\n",
    "for i in range(beam_size):\n",
    "    print(i, tokenizer.decode(outputs[i], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4. extract & rank outputs via the base model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
      "You may ignore this warning if your `pad_token_id` (50256) is identical to the `bos_token_id` (50256), `eos_token_id` (50256), or the `sep_token_id` (None), and your input is not padded.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. \u001b[1m A young boy is riding a bike in a park.\u001b[0m\n",
      "1. \u001b[1m A young girl is riding a bike in a park.\u001b[0m\n",
      "2. \u001b[1m A young boy is riding a bike in the park.\u001b[0m\n",
      "3. \u001b[1m A man and woman riding a bike in a park.\u001b[0m\n",
      "4. \u001b[1m A young girl is riding a bike in the park.\u001b[0m\n",
      "5. \u001b[1m A young man is riding a bike in a park.\u001b[0m\n",
      "6. \u001b[1m A young man is riding a bike in the park.\u001b[0m\n",
      "7. \u001b[1m riding a bike in a park on a sunny day.\u001b[0m\n",
      "8. \u001b[1m A man and woman riding a bike in the park.\u001b[0m\n",
      "9. \u001b[1m A young boy is riding a bike on the beach.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# extract the generated ids; removing prompt ids; remove suffix ids that are (partially) generated\n",
    "generated_ids = ctrlg.extract_generated_ids(outputs.tolist(), prompt_ids, suffix_ids, eos_token_id)\n",
    "\n",
    "# rank the generated ids by the base_model probability\n",
    "generated_ids = ctrlg.rank_generated_ids(base_model, generated_ids, prompt_ids, suffix_ids)\n",
    "\n",
    "# print top 10 outputs\n",
    "for idx, generated in enumerate(generated_ids[:10]):\n",
    "    print(f'{idx}. ' + tokenizer.decode(prefix_ids, skip_special_tokens=True) + \\\n",
    "          '\\033[1m' + tokenizer.decode(generated, skip_special_tokens=True) + '\\033[0m' + \\\n",
    "          tokenizer.decode(suffix_ids, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5. try some other constraints! (example constraint 2)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.  on a fine sunny\u001b[1m day a young girl is walking her dog\u001b[0m in the park.\n",
      "1.  on a fine sunny\u001b[1m day a young boy and his dog are playing\u001b[0m in the park.\n",
      "2.  on a fine sunny\u001b[1m day a young boy is playing with his dog\u001b[0m in the park.\n",
      "3.  on a fine sunny\u001b[1m day a boy and his dog are playing\u001b[0m in the park.\n",
      "4.  on a fine sunny\u001b[1m day a young boy and his dog are walking\u001b[0m in the park.\n",
      "5.  on a fine sunny\u001b[1m day a young girl and her dog are playing\u001b[0m in the park.\n",
      "6.  on a fine sunny\u001b[1m day a young girl and her dog are walking\u001b[0m in the park.\n",
      "7.  on a fine sunny\u001b[1m day a young girl is playing with her dog\u001b[0m in the park.\n",
      "8.  on a fine sunny\u001b[1m day a girl is walking her dog\u001b[0m in the park.\n",
      "9.  on a fine sunny\u001b[1m day a young boy and his dog are relaxing\u001b[0m in the park.\n"
     ]
    }
   ],
   "source": [
    "vocab_size = hmm_model.vocab_size\n",
    "eos_token_id = hmm_model.eos_token_id\n",
    "\n",
    "\n",
    "prefix = ' on a fine sunny' # generate text starting with ' on a fine sunny'\n",
    "suffix = ' in the park.<|endoftext|>' # generate text ending with ' in the park.<|endoftext|>'\n",
    "prompt = '<|endoftext|> on a fine sunny' # prompt the base model with the '<|endoftext|>' token and the prefix\n",
    "\n",
    "prefix_ids = tokenizer.encode(prefix)\n",
    "suffix_ids = tokenizer.encode(suffix)\n",
    "prompt_ids = tokenizer.encode(prompt)\n",
    "\n",
    "\n",
    "ac_builder = ctrlg.AhoCorasickBuilder(vocab_size)\n",
    "word_count_builder = ctrlg.WordCountBuilder(tokenizer, vocab_size)\n",
    "\n",
    "dfa_graphs = []\n",
    "# constraint 1:\n",
    "# one of ' girl', ' boy', ' girls', ' boys', ' children' AND\n",
    "# one of ' dogs', ' cats', ' dog', ' cat' have to appear\n",
    "# in the GIVEN ORDER.\n",
    "keyphrases = [[' girl', ' boy', ' girls', ' boys', ' children'],\n",
    "            [' dogs', ' cats', ' dog', ' cat']]\n",
    "for keyphrase in keyphrases:\n",
    "    patterns = [tokenizer.encode(x) for x in keyphrase]\n",
    "    dfa_graphs.append(ac_builder.build(patterns))\n",
    "# concatenate the patterns so they appear in the given order\n",
    "dfa_graphs = [ctrlg.DFA_concatenate(dfa_graphs)]\n",
    "\n",
    "# constraint 2: generate 7 - 12 words\n",
    "a, b = 7, 12\n",
    "dfa_graphs.append(word_count_builder.build(a, b))\n",
    "\n",
    "dfa_graph = ctrlg.DFA_prod(dfa_graphs, mode='intersection')\n",
    "dfa_model = ctrlg.DFAModel(dfa_graph, vocab_size).to(device)\n",
    "\n",
    "\n",
    "min_new_tokens = 5\n",
    "max_new_tokens = 32\n",
    "\n",
    "\n",
    "# initialze the constraints logits processor\n",
    "constraint_logits_processor = ctrlg.ConstraintLogitsProcessor(\n",
    "    hmm_model, dfa_model,\n",
    "    min_new_tokens, max_new_tokens,\n",
    "    prompt_ids, prefix_ids=prefix_ids, suffix_ids=suffix_ids)\n",
    "\n",
    "\n",
    "beam_size = 128\n",
    "constraint_logits_processor.hmm_batch_size = beam_size\n",
    "input_ids = torch.tensor([prompt_ids], device=device)\n",
    "# generate with beam search\n",
    "outputs = base_model.generate(\n",
    "        input_ids=input_ids, do_sample=False,\n",
    "        num_beams=beam_size, num_return_sequences=beam_size,\n",
    "        min_new_tokens=min_new_tokens, max_new_tokens=max_new_tokens,\n",
    "        logits_processor=LogitsProcessorList([constraint_logits_processor]),\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "    )\n",
    "\n",
    "# extract the generated ids; removing prompt ids; remove suffix ids that are (partially) generated\n",
    "generated_ids = ctrlg.extract_generated_ids(outputs.tolist(), prompt_ids, suffix_ids, eos_token_id)\n",
    "\n",
    "# rank the generated ids by the base_model probability\n",
    "generated_ids = ctrlg.rank_generated_ids(base_model, generated_ids, prompt_ids, suffix_ids)\n",
    "\n",
    "# print top 10 outputs\n",
    "for idx, generated in enumerate(generated_ids[:10]):\n",
    "    print(f'{idx}. ' + tokenizer.decode(prefix_ids, skip_special_tokens=True) + \\\n",
    "          '\\033[1m' + tokenizer.decode(generated, skip_special_tokens=True) + '\\033[0m' + \\\n",
    "          tokenizer.decode(suffix_ids, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Part B**. Ctrl-G on TULU2-7B (more computation required)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1. load pretrained models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'  # set your cuda device\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "\n",
    "import torch\n",
    "import ctrlg\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, LogitsProcessorList\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "# load the pretrained base_model and hmm_model;\n",
    "BASE_MODEL_PATH = f'ctrlg/tulu2-7b_writing-prompts'\n",
    "HMM_MODEL_PATH = f'ctrlg/hmm_tulu2-7b_writing-prompts_32768'\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(BASE_MODEL_PATH).to(device)\n",
    "base_model.eval()\n",
    "base_model.half() # fp16 inference\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_PATH)\n",
    "hmm_model = ctrlg.HMM.from_pretrained(HMM_MODEL_PATH).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2. specify logical constraints as DFAs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = hmm_model.vocab_size\n",
    "eos_token_id = hmm_model.eos_token_id\n",
    "\n",
    "prefix = 'Once upon a time, in a land far, far away, there was a kingdom. The kingdom was'\n",
    "suffix = 'beautiful buildings. The people of this kingdom were known for their kindness and generosity, always ready to lend a helping hand.</s>'\n",
    "soft_constraint = ' in fairytale style' # use empty string for no soft constraint\n",
    "prompt = f'<|user|>\\nContinue the given text{soft_constraint}:\\n{prefix}\\n<|assistant|>\\n'\n",
    "\n",
    "prefix_ids = tokenizer.encode(prefix)[1:]\n",
    "suffix_ids = tokenizer.encode(suffix)[1:]\n",
    "prompt_ids = tokenizer.encode(prompt)\n",
    "\n",
    "ac_builder = ctrlg.AhoCorasickBuilder(vocab_size)\n",
    "eos_builder = ctrlg.EOSBuilder(vocab_size, eos_token_id)\n",
    "\n",
    "dfa_graphs = []\n",
    "keyphrases = [['towering'], ['reach the sky'], ['reflected'], ['lake']]\n",
    "for keyphrase in keyphrases:\n",
    "    patterns = [tokenizer.encode(x)[1:] for x in keyphrase]\n",
    "    dfa_graphs.append(ac_builder.build(patterns))\n",
    "dfa_graphs.append(eos_builder.build())\n",
    "\n",
    "dfa_graph = ctrlg.DFA_prod(dfa_graphs, mode='intersection')\n",
    "dfa_model = ctrlg.DFAModel(dfa_graph, vocab_size).to(device)\n",
    "\n",
    "min_new_tokens = 16\n",
    "max_new_tokens = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3. generate with constraints.\n",
    "\n",
    "Due to the use of @torch.compile, the first run of the following functions could be significantly slower than the later runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialze the constraints logits processor\n",
    "constraint_logits_processor = ctrlg.ConstraintLogitsProcessor(\n",
    "    hmm_model, dfa_model,\n",
    "    min_new_tokens, max_new_tokens,\n",
    "    prompt_ids, prefix_ids=prefix_ids, suffix_ids=suffix_ids)\n",
    "\n",
    "\n",
    "# set the hmm_batch_size & temperature\n",
    "beam_size = 128 # sample 128 sequences\n",
    "temperature = 0.7\n",
    "constraint_logits_processor.hmm_batch_size = beam_size\n",
    "constraint_logits_processor.temperature = temperature\n",
    "\n",
    "\n",
    "# generate with sampling, temperature=0.7\n",
    "input_ids = torch.tensor([prompt_ids], device=device)\n",
    "outputs = base_model.generate(\n",
    "        input_ids=input_ids, do_sample=True,\n",
    "        num_return_sequences=beam_size, \n",
    "        min_new_tokens=min_new_tokens, max_new_tokens=max_new_tokens,\n",
    "        logits_processor=LogitsProcessorList([constraint_logits_processor]),\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "    )\n",
    "\n",
    "\n",
    "# extract the generated ids; removing prompt ids; remove suffix ids that are (partially) generated\n",
    "generated_ids = ctrlg.extract_generated_ids(outputs.tolist(), prompt_ids, suffix_ids, eos_token_id)\n",
    "\n",
    "# filter 75% of the generated ids by how well they connect with the suffix\n",
    "generated_ids = ctrlg.rank_generated_ids(base_model, generated_ids, prompt_ids, suffix_ids,\n",
    "                                            suffix_logits_only=True, suffix_length_cap=5)[:32]\n",
    "# rank the generated ids by the base_model for higher quality\n",
    "generated_ids = ctrlg.rank_generated_ids(base_model, generated_ids, prompt_ids, suffix_ids)\n",
    "\n",
    "# print top 10 outputs\n",
    "for idx, generated in enumerate(generated_ids[:10]):\n",
    "    print(f'{idx}. ' + tokenizer.decode(prefix_ids, skip_special_tokens=True) + \\\n",
    "          ' ' + '\\033[1m' + tokenizer.decode(generated, skip_special_tokens=True) + '\\033[0m' + ' ' + \\\n",
    "          tokenizer.decode(suffix_ids, skip_special_tokens=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
